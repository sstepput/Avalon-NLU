<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description" content="Long-Horizon Dialogue Understanding for Role Identification in the Game of Avalon with Large Language Models">
    <meta name="keywords" content="Avalon: The Resistance, Natural Language Understanding, Dialogue Systems, EMNLP 2023">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Long-Horizon Dialogue Understanding for Role Identification in the Game of Avalon with Large Language Models</title>
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="stylesheet" href="./static/css/custom.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">Long-Horizon Dialogue Understanding for Role Identification in the Game of Avalon with Large Language Models</h1>
                        <div class="is-size-5 publication-authors">

                            <span class="author-block">
                                    <a href="https://simonstepputtis.com">Simon Stepputtis</a><sup>1</sup>,</span>
                            <span class="author-block">
                                <a href="https://sites.google.com/asu.edu/jcampbell/">Joseph Campbell</a><sup>1</sup>,</span>
                            <span class="author-block"></span>Yaqi Xie<sup>1</sup>,</span>
                            <span class="author-block"></span>Zhengyang Qi<sup>1</sup>,</span>
                            <span class="author-block"></span>Wenxin Sharon Zhang<sup>1</sup>,</span>
                            <span class="author-block"></span>Ruiyi Wang<sup>1</sup>,</span>
                            <span class="author-block"></span>Sanketh Rangreji<sup>1</sup>,</span>
                            <span class="author-block"></span>Charles Michael Lewis<sup>2</sup>,</span>
                            <span class="author-block"></span>Katia P. Sycara<sup>1</sup></span>
                        </div>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>1</sup><i>Carnegie Melon University</i>, <sup>2</sup><i>University of Pittsburgh</i></span>
                        </div>
                        <br>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">Presented at the <b><i>Findings of the Association for Computational Linguistics</i></b> - EMNLP 2023</span>
                        </div>
                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <span class="link-block">
                                    <a href="#"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                <span>Paper</span>
                                </a>
                                </span>
                                </span>
                                <span class="link-block">
                                    <a href="#"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                <span>Dataset and Testbed</span>
                                </a>
                                </span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <!-- <div class="columns is-centered">

                <div class="column">
                    <div class="content">
                        <img src="static/assets/animation.gif" alt="Simulation task" width="70%" style="margin-left: 15%;">
                    </div>
                </div>

            </div> -->

            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            Deception and persuasion play a critical role in long-horizon dialogues between multiple parties, especially when the interests, goals, and motivations of the participants are not aligned. Such complex tasks pose challenges for current Large Language
                            Models (LLM) as deception and persuasion can easily mislead them, especially in long-horizon multi-party dialogues. To this end, we explore the game of <i>Avalon: The Resistance</i>, a social deduction
                            game in which players must determine each other's hidden identities to complete their team's objective. We introduce an online test bed and a dataset containing 20 carefully collected and labeled games among human players that
                            exhibit long-horizon deception in a cooperative-competitive setting. We discuss the capabilities of LLMs to utilize deceptive long-horizon conversations between six human players to determine each player's goal and motivation.
                            Particularly, we discuss the multimodal integration of the chat between the players and the game's state that grounds the conversation, providing further insights into the true player identities. We find that even current state-of-the-art
                            LLMs do not reach human performance, making our dataset a compelling benchmark to investigate the decision-making and language-processing capabilities of LLMs.
                        </p>
                    </div>
                </div>
            </div>
            <!--/ Abstract. -->

            <!-- Paper video. -->
            <!-- <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Introduction Video (7 Minutes)</h2>
                    <div class="publication-video">
                        <iframe width="560" height="315" src="https://www.youtube.com/embed/S4GyhYA7HtE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
                    </div>
                </div>
            </div> -->
            <!--/ Paper video. -->
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">

            <div class="columns is-centered">
                <!-- Visual Effects. -->
                <div class="column">
                    <div class="content">
                        <h2 class="title is-4">Avalon Dataset</h2>
                        <img src="static/assets/ds.gif" onmouseover="this.src='static/assets/ds.gif'" alt="Avalon Dataset" width="70%" style="margin-left: 15%;">
                        <p>
                            20 games played by 30 users across 19 unique teams. Over 24 hours of playtime with full game chat, game state, player beliefs, as well as persuasion and deception strategies.
                        </p>
                    </div>
                </div>
                <!--/ Visual Effects. -->

                <!-- Matting. -->
                <div class="column">
                    <div class="content">
                        <h2 class="title is-4">Game Representation</h2>
                        <img src="static/assets/game_states.png" alt="State Representation" width="70%" style="margin-left: 15%;">
                        <p>
                            The game's context (i.e., chat and game state) is represented either from the beginning of the game (green), or in a round-based manner (yellow), utilizing a carried over belief of player roles.
                        </p>
                    </div>
                </div>

                <!-- Matting. -->
                <div class="column">
                    <div class="content">
                        <h2 class="title is-4">Role Prediction</h2>
                        <img src="static/assets/role_prediction.png" alt="Role Prediction" width="70%" style="margin-left: 15%;">
                        <p>
                            We evaluate GPT-4, GPT-3.5, and Llama-2 (including fine-tune versions of GPT-3.5 and Llama-2) predicting each palyer's role and find that such model struggle with such complex NLU tasks.
                        </p>
                    </div>
                </div>
            </div>

            <div class="columns is-centered ">
                <div class="column is-full-width">
                    <h2 class="title is-3"><span class="dcliport">Dataset Overview</span></h2>

                    We present a novel benchmark, associated dataset, and testbed (see our GitHub) for long-horizon dialogue understanding in scenarios of conflicting interests among multiple participants. This task combines utterances from six human players at a time, hand-labeled
                    persuasion and deception strategies, player beliefs, and comprehensive game states recorded over more than 24 hours of gameplay. We demonstrate that current state-of-the-art LLMs do not reach human-level performance in environments
                    that require the understanding and tracking of <i>long-horizon</i> dialogue between multiple participants in challenging social cooperative-competitive settings. Compared to similar datasets, our benchmark contains
                    longer context horizons, stricter game rules, and high-quality dialogue, making it well-suited for NLU research as all game-relevant communication has been captured and is thus, available to learning algorithms. In our interactive
                    demo below, you can check out one the data collected during one of our games in an interactive manner.

                    <br><br> Our main contributions are as follows:
                    <ul>
                        <li>A testbed and dataset containing 2384 utterances from 20 human player games hand-annotated with strategies (persuasion and deception), player beliefs, and game state.</li>
                        <li>A comprehensive analysis of LLM performance in our proposed multimodal long-horizon dialogue understanding benchmark, including persuasive and deceptive behavior.</li>
                        <li>An exploration of the limitations of current models and the introduction of state representations that can improve long-horizon dialogue modeling.</li>
                    </ul>
                    <br>

                    <h3 class="title is-4"><span class="dcliport">Interactive Example</span></h3>
                    <div class="desk">
                        The following is an example game from our dataset of current 20 games. Please utilize the respective round and turn selectors to "scroll" through the game. In the dataset available on our GitHub, each game is represented as a JSON file that containing
                        all the information presented in the demonstration below.
                        <iframe src="https://avalon-nlu.streamlit.app/?embed=true&embed_options=light_theme" height="1000px" style="width:100%;border:none;"></iframe>
                    </div>
                    <div class="div-only-mobile">
                        Our dataset of currently 20 games contains the following information: Chat among the six players, hand-labeled persuasion strategies, hand-labeled deception strategies for all evil players, beliefs over what players though about other players at different
                        stages of the game, as well as the full game state containing proposed parties and vote outcomes.
                        <br> <br><b>Note:</b> <i>For non-mobile devices, this website provides an interactive demo of our dataset.</i>
                    </div>

                </div>
            </div>
    </section>

    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            If you find this work useful, please add the following citation to your work.
            <pre><code>@inproceedings{stepputtis2023longhorizon,
    title={Long-Horizon Dialogue Understanding for Role Identification in the Game of Avalon with Large Language Models},
    author={Stepputtis, Simon and Campbell, Joseph and Xie, Yaqi and Qi, Zhengyang and Zhang, Wenxin Sharon and Wang, Ruiyi and Rangreji, Sanketh and Lewis, Charles Michael and Sycara, Katia},
    booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
    year={2023},
    url={https://openreview.net/forum?id=JKmsjKJ0Q8}
}</code></pre>
        </div>
    </section>


    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column">
                    <div class="content has-text-centered">
                        <p>
                            Website template borrowed from <a href="https://github.com/nerfies/nerfies.github.io">NeRFies</a> made by <a href="https://keunhong.com/">Keunhong Park</a>.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>
</body>

</html>